# ğŸ”¬ GPT-OSS DeepResearch Evaluation

Evaluation framework for deep research agents with local/remote search engines and multiple LLM backends.

---

## ğŸ“‹ Table of Contents

- [ğŸ—‚ï¸ Data Preparation](#data-preparation)
- [ğŸ“¦ Installation](#installation)
- [âš™ï¸ Configuration](#configuration)
- [ğŸš€ Get Started](#get-started)
- [ğŸ“Š Benchmarks](#benchmarks)
- [ğŸ“ Script Parameters](#script-parameters)
- [ğŸ“ˆ Evaluation](#evaluation)

---

## ğŸ› ï¸ Environment Setup

### ğŸ’» System Dependencies

```bash
sudo apt install -y openjdk-21-jdk
```

### ğŸ Python Dependencies

```bash
uv venv --python 3.12
source .venv/bin/activate
```

### ğŸ” Tevatron (for BrowseComp-Plus local search)

```bash
uv pip install -e .

git clone https://github.com/texttron/tevatron.git
cd tevatron
uv pip install -e .
cd ..
```

---

## ğŸ—‚ï¸ Data Preparation

### ğŸ” Local Search Engine (For BrowseComp-Plus)

To run **BrowseComp-Plus** benchmark with local search, you need to download the queries, corpus, and indexes:

**1ï¸âƒ£ Download BrowseComp-Plus Queries (Required):**
```bash
# Create data directory
mkdir -p Tevatron/browsecomp-plus/data

# Download queries (contains questions, answers, and relevance judgements)
hf download Tevatron/browsecomp-plus \
    --repo-type dataset \
    --local-dir Tevatron/browsecomp-plus
```

**2ï¸âƒ£ Download BrowseComp-Plus Corpus:**
```bash
# Create corpus directory
mkdir -p Tevatron/browsecomp-plus-corpus/data
mkdir -p Tevatron/browsecomp-plus-indexes

# Download corpus (parquet files with document texts)
hf download Tevatron/browsecomp-plus-corpus \
    --repo-type dataset \
    --local-dir Tevatron/browsecomp-plus-corpus
```

**3ï¸âƒ£ Download Search Indexes:**
```bash
# BM25 Index (lightweight, recommended)
hf download Tevatron/browsecomp-plus-indexes \
    --repo-type dataset \
    --include "bm25/*" \
    --local-dir Tevatron/browsecomp-plus-indexes

# Dense Index (optional, requires GPU)
hf download Tevatron/browsecomp-plus-indexes \
    --repo-type dataset \
    --include "qwen3-embedding-8b/*" \
    --local-dir Tevatron/browsecomp-plus-indexes
```

**4ï¸âƒ£ Download Lucene JARs (for BM25 highlighting):**
```bash
mkdir -p tevatron
cd tevatron
wget https://repo1.maven.org/maven2/org/apache/lucene/lucene-highlighter/9.9.1/lucene-highlighter-9.9.1.jar
wget https://repo1.maven.org/maven2/org/apache/lucene/lucene-queries/9.9.1/lucene-queries-9.9.1.jar
wget https://repo1.maven.org/maven2/org/apache/lucene/lucene-memory/9.9.1/lucene-memory-9.9.1.jar
cd ..
```

---

## ğŸ“¦ Installation

### âš¡ Quick Setup (Recommended)

Run the setup script to install all dependencies automatically:

```bash
bash setup.sh
```

**ğŸ“Œ This script will:**
- âœ… Install Python 3.12 virtual environment using `uv`
- âœ… Install all Python dependencies
- âœ… Install Tevatron for local search
- âœ… Download Lucene JARs
- âœ… Download corpus and indexes (optional, interactive)

---

## âš™ï¸ Configuration

### ğŸ”‘ API Keys

Copy the template and configure your API keys:

```bash
cp .env.template .env
```

Edit `.env`:
```bash
# Serper API (for web search when using browser_backend=serper)
SERPER_API_KEY=your_key        # Get from: https://serper.dev/

# OpenAI API (for evaluation scoring)
OPENAI_API_KEY=your_key        # Get from: https://platform.openai.com/api-keys
```

---

## ğŸš€ Get Started

### ğŸ“– Example 1: BrowseComp-Plus with Local Search Engine

**Complete workflow using local Dense search:**

```bash
# Terminal 1: Start local Dense search service on port 8000
bash scripts/start_search_service.sh dense 8000

# Terminal 2: Start vLLM servers (requires 4 GPUs)
# TP=2, deploy 2 servers starting from port 8001 on GPUs 0,1,2,3
bash scripts/start_nemotron_servers.sh 2 8001 0,1,2,3

# Terminal 3: Run agent
bash run_agent.sh results/browsecomp_plus/Researcher_dense 8001 2 browsecomp_plus local OpenResearcher/Nemotron-3-Nano-30B-A3B
```

**ğŸ’¡ What this does:**
- ğŸ” Deploys Dense search on port 8000 as virtual search engine
- ğŸ–¥ï¸ Launches 2 vLLM servers (ports 8001, 8002) with TP=2 across 4 GPUs
- ğŸ¤– Runs agent with load balancing across both servers

### ğŸ“– Example 2: Using Serper API (No Local Search Needed)

**Run with Serper Google Search API:**

```bash
# Terminal 1: Start vLLM servers (requires 4 GPUs)
bash scripts/start_nemotron_servers.sh 2 8001 0,1,2,3

# Terminal 2: Run agent with serper search backend
bash run_agent.sh results/gaia/OpenResearcher_serper 8001 2 gaia serper OpenResearcher/Nemotron-3-Nano-30B-A3B
```

**ğŸŒ Browser Backend Options:**
- `local` - Use local BM25/Dense search service (for BrowseComp-Plus)
- `serper` - Use Serper Google Search API (for all other benchmarks)

For other parameters, please refer to [ğŸ“„ assets/docs/parameter.md](assets/docs/parameter.md).

---

## ğŸ“Š Benchmarks

| Benchmark | Dataset Key | Size | Language | Search Backend | Description |
|-----------|-------------|------|----------|----------------|-------------|
| ğŸŒ **BrowseComp** | `browsecomp` | 1266 | EN | serper | OpenAI public browse benchmark |
| ğŸ”¬ **BrowseComp-Plus** | `browsecomp-plus` | 830 | EN | local | Deep-research benchmark isolating retriever and LLM agent effects |
| ğŸ¤– **GAIA-text** | `gaia` | 103 | EN | serper | Text-only subset of GAIA benchmark (dev split) |
| ğŸ‡¨ğŸ‡³ **XBench** | `xbench` | 100 | ZH | serper | DeepSearch benchmark with encrypted test cases |
| ğŸ“š **SealQA-ref** | `seal_ref` | 111 | EN | serper | With reference URLs |

For other benchmarks, please refer to [ğŸ“ assets/docs](assets/docs).

### âš¡ Quick Commands

| Scenario | Command |
|----------|---------|
| ğŸŒ **BrowseComp** | `bash run_agent.sh results/browsecomp 8001 2 browsecomp serper OpenResearcher/Nemotron-3-Nano-30B-A3B` |
| ğŸ”¬ **BrowseComp+ (BM25)** | `bash scripts/start_search_service.sh bm25 8000` then `bash run_agent.sh results/browsecomp-plus/OpenResearcher_bm25 8001 2 browsecomp-plus local OpenResearcher/Nemotron-3-Nano-30B-A3B` |
| ğŸ”¬ **BrowseComp+ (Dense)** | `bash scripts/start_search_service.sh dense 8000` then `bash run_agent.sh results/browsecomp-plus/OpenResearcher_dense 8001 2 browsecomp-plus local OpenResearcher/Nemotron-3-Nano-30B-A3B` |
| ğŸ¤– **GAIA** | `bash run_agent.sh results/gaia 8001 2 gaia serper OpenResearcher/Nemotron-3-Nano-30B-A3B` |
| ğŸ‡¨ğŸ‡³ **XBench** | `bash run_agent.sh results/xbench 8001 2 xbench serper OpenResearcher/Nemotron-3-Nano-30B-A3B` |

---

## ğŸ“ˆ Evaluation

After running experiments, evaluate results:

```bash
python eval.py --input_dir results/browsecomp_plus_dense/OpenResearcher
```

---

## ğŸ“œ License

