# ─────────────────────────────────────────────────────────────
# Offline Search Service Configuration
# Usage: SEARCH_CONFIG=search_config.yaml uvicorn scripts.search_webui:app ...
#        or simply: bash scripts/start_search_webui.sh [this_file]
# ─────────────────────────────────────────────────────────────

# ── Web service ──────────────────────────────────────────────
service:
  host: "127.0.0.1"
  port: 8000
  max_snippet_len: 300          # Max characters shown in search result snippets

# ── Corpus (Parquet files: docid / url / text) ───────────────
corpus:
  name: "BrowseComp-Plus"       # Display name shown in the UI
  # Supports glob patterns, e.g. /path/to/data/*.parquet
  parquet_path: "/mnt/fk-data/moe/bianhaiyang/data/agent/Tevatron/browsecomp-plus-corpus/data/*.parquet"

# ── Retrieval engine ─────────────────────────────────────────
engine:
  type: "dense"                  # "bm25"  →  keyword retrieval (no GPU needed)
                                # "dense" →  semantic retrieval (GPU required)

  # Settings for BM25 (only used when type: bm25)
  bm25:
    index_dir: "/mnt/fk-data/moe/bianhaiyang/data/agent/Tevatron/browsecomp-plus-indexes/bm25"

  # Settings for Dense (only used when type: dense)
  dense:
    index_path: "/mnt/fk-data/moe/bianhaiyang/data/agent/Tevatron/browsecomp-plus-indexes/qwen3-embedding-8b/*.pkl"
    model_name: "/home/bianhaiyang/modelhub/Qwen/Qwen3-Embedding-8B"
    gpu_ids: ["0", "1", "2"]              # Logical indices after CUDA_VISIBLE_DEVICES remapping (always start from 0)
    cuda_visible_devices: "1,2,7"         # Physical GPUs to use (comma-separated). These become logical 0,1,2 inside the process.

# ── Lucene JARs (needed by both BM25 and snippet highlighting) ─
lucene:
  # Directory containing lucene-highlighter/queries/memory *.jar files
  # These are downloaded by setup.sh into the tevatron/ subfolder.
  extra_dir: "/mnt/fk-data/moe/bianhaiyang/projects/OpenResearcher/tevatron"
